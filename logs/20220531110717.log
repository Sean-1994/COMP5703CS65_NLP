INFO - 2022-05-31 11:08:21,551 - process: 6112 - build.py - polls.build - 24 - build - successfully build project health_redis to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\health_redis\health_redis-1.0-py3.10.egg
ERROR - 2022-05-31 11:08:27,450 - process: 6112 - utils.py - polls.utils - 84 - utils - E:\python\lib\site-packages\scrapy\utils\project.py:81: ScrapyDeprecationWarning: Use of environment variables prefixed with SCRAPY_ to override settings is deprecated. The following environment variables are currently defined: EGG_VERSION
  warnings.warn(
Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 88, in walk_modules
    submod = import_module(fullpath)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health_redis-1653966506-i_3p_6jy.egg\health_redis\spiders\healthdir.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 482, in project_deploy
    scrapyd.add_version(project_name, int(time.time()), egg_file.read())
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 76, in add_version
    json = self.client.post(url, data=data, files=files,
  File "E:\python\lib\site-packages\requests\sessions.py", line 577, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: E:\python\lib\site-packages\scrapy\utils\project.py:81: ScrapyDeprecationWarning: Use of environment variables prefixed with SCRAPY_ to override settings is deprecated. The following environment variables are currently defined: EGG_VERSION
  warnings.warn(
Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 88, in walk_modules
    submod = import_module(fullpath)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health_redis-1653966506-i_3p_6jy.egg\health_redis\spiders\healthdir.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 11:24:17,355 - process: 6112 - build.py - polls.build - 24 - build - successfully build project health_redis to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\health_redis\project-1.0-py3.10.egg
ERROR - 2022-05-31 11:24:28,703 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-uyf1kdww.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-uyf1kdww.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 11:25:11,263 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-cub4m7pq.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-cub4m7pq.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 11:27:58,874 - process: 6112 - build.py - polls.build - 24 - build - successfully build project HopkinsSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\HopkinsSpider\HopkinsSpider-1.0-py3.10.egg
ERROR - 2022-05-31 11:28:07,739 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-h83khlfw.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-h83khlfw.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 11:29:11,540 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-qkfmjkpb.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-qkfmjkpb.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 11:36:04,843 - process: 6112 - build.py - polls.build - 24 - build - successfully build project HopkinsSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\HopkinsSpider\HopkinsSpider-1.0-py3.10.egg
ERROR - 2022-05-31 11:36:35,778 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-0_95u15b.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-0_95u15b.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 11:40:45,078 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C871030>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C871030>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C871030>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C871030>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:45,081 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C871930>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C871930>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C871930>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C871930>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:45,082 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C871D50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C871D50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C871D50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C871D50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:47,259 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8DE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8DE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8DE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8DE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:47,275 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C7BB8E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C7BB8E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C7BB8E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C7BB8E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:47,299 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C872E60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C872E60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C872E60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C872E60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:50,056 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C0820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8C0820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C0820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C0820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:52,060 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8EC2E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8EC2E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8EC2E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8EC2E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:52,064 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ED7E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8ED7E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ED7E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ED7E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:52,064 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ED600>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8ED600>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ED600>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ED600>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:52,103 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C9900>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8C9900>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C9900>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C9900>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:57,061 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CAAD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8CAAD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CAAD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CAAD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:57,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8720E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8720E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8720E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8720E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:57,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CBFD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8CBFD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CBFD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CBFD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:40:57,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C873E80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C873E80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C873E80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C873E80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:41:02,068 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C826F80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C826F80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C826F80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C826F80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:41:02,069 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C825E70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C825E70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C825E70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C825E70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:41:02,071 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C928670>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C928670>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C928670>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C928670>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:41:02,073 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C929330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C929330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C929330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C929330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:41:05,143 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,143 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,143 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,144 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,144 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,144 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,145 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,145 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,145 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,145 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,146 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,146 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,146 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,146 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,147 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,147 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,148 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,148 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,149 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,149 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,149 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,150 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,150 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,150 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,150 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,150 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,150 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,151 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,151 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,151 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,151 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,151 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,152 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,152 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,152 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,152 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,152 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,153 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,153 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,153 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,153 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,153 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,154 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,154 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,155 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,155 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,155 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,156 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:05,156 - process: 6112 - utils.py - polls.utils - 84 - utils - ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
ConnectionResetError: [WinError 10054] 远程主机强迫关闭了一个现有的连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 769, in reraise
    raise value.with_traceback(tb)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 501, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(10054, '远程主机强迫关闭了一个现有的连接。', None, 10054, None))
ERROR - 2022-05-31 11:41:07,062 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ECC10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8ECC10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ECC10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ECC10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:41:07,064 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8EEC80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8EEC80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8EEC80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8EEC80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:41:07,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ECE80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8ECE80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ECE80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8ECE80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:41:07,066 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8EFFD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8EFFD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8EFFD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8EFFD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:41:22,856 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-dzu2w51u.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-dzu2w51u.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 11:41:27,967 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-v95j22cw.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-v95j22cw.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 11:44:15,673 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-of0brsoz.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-of0brsoz.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 11:45:40,076 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C0DF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8C0DF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C0DF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C0DF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:42,116 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8DF610>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8DF610>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8DF610>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8DF610>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:45,059 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C122470>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C122470>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C122470>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C122470>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:45,062 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C0B1A50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C0B1A50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C0B1A50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C0B1A50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:45,073 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4C9A20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C4C9A20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4C9A20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4C9A20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:47,055 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4CBB50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C4CBB50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4CBB50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4CBB50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:47,141 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BCA90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8BCA90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BCA90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BCA90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:47,167 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF09AB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31BF09AB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF09AB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF09AB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:47,173 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF09870>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31BF09870>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF09870>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF09870>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:52,068 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A2BF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5A2BF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A2BF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A2BF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:52,068 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A3790>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5A3790>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A3790>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A3790>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:52,069 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A1E70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5A1E70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A1E70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A1E70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:52,069 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C01C700>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C01C700>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C01C700>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C01C700>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:57,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C8F10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8C8F10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C8F10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C8F10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:57,067 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CAC50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8CAC50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CAC50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CAC50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:57,070 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C9E10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8C9E10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C9E10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8C9E10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:45:57,072 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CB460>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8CB460>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CB460>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8CB460>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:02,062 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D4550>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5D4550>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D4550>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D4550>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:02,062 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7550>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5D7550>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7550>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7550>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:02,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D6F50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5D6F50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D6F50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D6F50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:02,066 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D60B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5D60B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D60B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D60B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:07,062 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF0A0E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31BF0A0E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF0A0E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF0A0E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:07,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF0A8C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31BF0A8C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF0A8C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF0A8C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:07,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF0BC40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31BF0BC40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF0BC40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF0BC40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:07,066 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF096C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31BF096C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF096C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31BF096C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:12,060 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C58D000>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C58D000>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C58D000>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C58D000>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:12,063 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4BE170>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C4BE170>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4BE170>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4BE170>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:12,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4BDC60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C4BDC60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4BDC60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4BDC60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:12,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4BE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C4BE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4BE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C4BE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:17,059 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7280>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5D7280>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7280>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7280>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:17,062 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7BB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5D7BB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7BB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7BB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:17,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7B50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5D7B50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7B50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D7B50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:17,065 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D5780>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5D5780>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D5780>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5D5780>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:21,657 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C571870>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C571870>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C571870>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C571870>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:21,658 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C570160>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C570160>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C570160>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C570160>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:21,669 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C570820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C570820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C570820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C570820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:21,669 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C570700>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C570700>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C570700>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C570700>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:26,460 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5CE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CE8F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:26,461 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CD000>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5CD000>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CD000>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CD000>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:26,462 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CCA30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5CCA30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CCA30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CCA30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:26,463 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CEA70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5CEA70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CEA70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5CEA70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:31,769 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A3250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5A3250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A3250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A3250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:31,771 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A3760>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5A3760>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A3760>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A3760>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:31,774 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A0CD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5A0CD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A0CD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A0CD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:31,774 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A0070>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C5A0070>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A0070>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C5A0070>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:37,071 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BDC90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8BDC90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BDC90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BDC90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:37,075 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BF5E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8BF5E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BF5E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BF5E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:37,075 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BCCD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8BCCD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BCCD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BCCD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:37,084 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BFB20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C8BFB20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BFB20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C8BFB20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:42,072 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F6D40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31D9F6D40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F6D40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F6D40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:42,075 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F7BB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31D9F7BB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F7BB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F7BB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:42,088 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F41C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31D9F41C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F41C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F41C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:42,089 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F64A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31D9F64A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F64A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31D9F64A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:47,064 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C870E80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31C870E80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C870E80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31C870E80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:47,066 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31DA90C10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31DA90C10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31DA90C10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31DA90C10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:47,067 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31DA91960>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31DA91960>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31DA91960>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31DA91960>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:47,067 - process: 6112 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31DA90AC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001B31DA90AC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31DA90AC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001B31DA90AC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 11:46:55,757 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-39whfy_p.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-39whfy_p.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 11:47:56,552 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-_b55320p.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-_b55320p.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 11:48:57,818 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-3iktsaya.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-3iktsaya.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 11:49:22,048 - process: 6112 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-uhcw556x.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-uhcw556x.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)


INFO - 2022-05-31 13:04:32,259 - process: 15832 - build.py - polls.build - 24 - build - successfully build project HopkinsSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\HopkinsSpider\HopkinsSpider-1.0-py3.10.egg
ERROR - 2022-05-31 13:04:39,729 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-wy9zu85u.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-wy9zu85u.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 13:05:47,941 - process: 15832 - build.py - polls.build - 24 - build - successfully build project HopkinsSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\HopkinsSpider\HopkinsSpider-1.0-py3.10.egg
ERROR - 2022-05-31 13:05:49,634 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Read timed out. (read timeout=3)
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 449, in _make_request
    six.raise_from(e, None)
  File "<string>", line 3, in raise_from
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 444, in _make_request
    httplib_response = conn.getresponse()
  File "E:\python\lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "E:\python\lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
  File "E:\python\lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
  File "E:\python\lib\socket.py", line 705, in readinto
    return self._sock.recv_into(b)
TimeoutError: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 550, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File "E:\python\lib\site-packages\urllib3\packages\six.py", line 770, in reraise
    raise value
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 451, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 340, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=6800): Read timed out. (read timeout=3)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 171, in client_status
    requests.get(scrapyd_url(client.ip, client.port), timeout=3)
  File "E:\python\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "E:\python\lib\site-packages\requests\api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 532, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=6800): Read timed out. (read timeout=3)
ERROR - 2022-05-31 13:06:39,650 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-qby8u32a.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-qby8u32a.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 13:08:32,257 - process: 15832 - build.py - polls.build - 24 - build - successfully build project HopkinsSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\HopkinsSpider\HopkinsSpider-1.0-py3.10.egg
ERROR - 2022-05-31 13:08:39,124 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-bbv_t9mu.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-bbv_t9mu.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 13:09:09,839 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804980D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191804980D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804980D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804980D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:09,839 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804991E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191804991E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804991E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804991E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:09,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049B760>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918049B760>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049B760>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049B760>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:09,844 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F37F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F37F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F37F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F37F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:14,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180856BC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180856BC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180856BC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180856BC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:14,845 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808579D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808579D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808579D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808579D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:14,846 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808545B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808545B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808545B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808545B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:14,852 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049ABC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918049ABC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049ABC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049ABC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:19,838 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D5C90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803D5C90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D5C90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D5C90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:19,840 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D5D80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803D5D80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D5D80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D5D80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:19,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D72B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803D72B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D72B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D72B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:19,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D5990>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803D5990>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D5990>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D5990>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:24,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B85330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B85330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B85330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B85330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:24,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808550F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808550F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808550F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808550F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:24,844 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B868F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B868F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B868F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B868F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:24,844 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B86200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B86200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B86200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B86200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:29,838 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180833DF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180833DF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180833DF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180833DF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:29,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180830640>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180830640>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180830640>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180830640>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:29,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180833E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180833E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180833E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180833E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:29,844 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180830CD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180830CD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180830CD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180830CD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:34,840 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B31D80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B31D80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B31D80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B31D80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:34,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180443E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180443E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180443E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180443E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:34,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180440280>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180440280>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180440280>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180440280>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:34,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180440220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180440220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180440220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180440220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:39,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CC430>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803CC430>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CC430>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CC430>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:39,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CCC70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803CCC70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CCC70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CCC70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:39,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CC7F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803CC7F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CC7F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CC7F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:39,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CEBC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803CEBC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CEBC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CEBC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:44,839 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F64D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808F64D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F64D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F64D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:44,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F73A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808F73A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F73A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F73A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:44,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F7FA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808F7FA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F7FA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F7FA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:44,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F7A60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808F7A60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F7A60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F7A60>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:49,840 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F6590>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808F6590>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F6590>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F6590>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:49,840 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F6080>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808F6080>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F6080>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F6080>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:49,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F6FE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808F6FE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F6FE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F6FE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:49,849 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F7100>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808F7100>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F7100>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808F7100>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:54,839 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180830310>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180830310>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180830310>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180830310>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:54,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808306D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808306D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808306D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808306D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:54,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808313F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808313F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808313F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808313F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:54,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808305E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808305E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808305E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808305E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:59,839 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A4CA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808A4CA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A4CA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A4CA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:59,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A4C10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808A4C10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A4C10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A4C10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:59,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A50C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808A50C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A50C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A50C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:09:59,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A6F80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808A6F80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A6F80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A6F80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:04,840 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804B5BD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191804B5BD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804B5BD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804B5BD0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:04,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918081F010>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918081F010>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918081F010>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918081F010>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:04,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918081FCA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918081FCA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918081FCA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918081FCA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:04,845 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918081E5C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918081E5C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918081E5C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918081E5C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:09,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B05330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B05330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B05330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B05330>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:09,841 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A6200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808A6200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A6200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808A6200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:09,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B05630>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B05630>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B05630>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B05630>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:09,844 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B05C90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B05C90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B05C90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B05C90>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:14,838 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B87220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B87220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B87220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B87220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:14,840 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B84730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B84730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B84730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B84730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:14,844 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B865F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B865F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B865F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B865F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:14,845 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B874F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B874F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B874F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B874F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:19,839 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804993F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191804993F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804993F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804993F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:19,845 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804985B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191804985B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804985B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191804985B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:19,846 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049A230>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918049A230>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049A230>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049A230>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:19,846 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180498D30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180498D30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180498D30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180498D30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:24,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2350>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F2350>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2350>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2350>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:24,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F38E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F38E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F38E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F38E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:24,843 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F3580>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F3580>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F3580>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F3580>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:24,844 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2860>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F2860>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2860>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2860>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:29,838 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049B250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918049B250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049B250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049B250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:29,840 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049BBE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918049BBE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049BBE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918049BBE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:29,842 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180498AF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180498AF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180498AF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180498AF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:29,844 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B32EC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B32EC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B32EC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B32EC0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:35,070 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D4820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803D4820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D4820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D4820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:35,074 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D7730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803D7730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D7730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D7730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:35,076 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D7340>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803D7340>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D7340>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D7340>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:35,076 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D6CB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803D6CB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D6CB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803D6CB0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:40,065 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CDD50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803CDD50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CDD50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CDD50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:40,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CC8E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803CC8E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CC8E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CC8E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:40,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CF4F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803CF4F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CF4F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CF4F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:40,068 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CDD20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803CDD20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CDD20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803CDD20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:45,065 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052C1F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918052C1F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052C1F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052C1F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:45,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052DAE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918052DAE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052DAE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052DAE0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:45,067 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052F2E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918052F2E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052F2E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052F2E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:45,068 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052C820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918052C820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052C820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052C820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:50,063 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B86410>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B86410>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B86410>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B86410>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:50,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180857640>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180857640>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180857640>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180857640>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:50,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180498250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180498250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180498250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180498250>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:50,067 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180854730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180854730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180854730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180854730>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:55,069 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B07310>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B07310>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B07310>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B07310>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:55,070 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B06830>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B06830>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B06830>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B06830>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:55,075 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B06F50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B06F50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B06F50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B06F50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:10:55,075 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B063E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B063E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B063E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B063E0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:00,059 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052CDF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918052CDF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052CDF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052CDF0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:00,063 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052E530>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918052E530>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052E530>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052E530>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:00,069 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052E560>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918052E560>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052E560>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052E560>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:00,071 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052CC10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918052CC10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052CC10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052CC10>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:05,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808577C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191808577C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808577C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191808577C0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:05,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180854F40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180854F40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180854F40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180854F40>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:05,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180856200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180856200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180856200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180856200>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:05,068 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180857E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180857E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180857E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180857E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:10,063 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180463B50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180463B50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180463B50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180463B50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:10,067 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803A7A30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803A7A30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803A7A30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803A7A30>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:10,067 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918044E7A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918044E7A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918044E7A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918044E7A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:10,077 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803A6770>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803A6770>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803A6770>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803A6770>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:15,063 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B335B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B335B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B335B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B335B0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:15,064 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B336D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B336D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B336D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B336D0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:15,065 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B33850>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B33850>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B33850>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B33850>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:15,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B33CA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x0000019180B33CA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B33CA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000019180B33CA0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:20,064 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E3F70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803E3F70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E3F70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E3F70>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:20,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E3220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803E3220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E3220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E3220>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:20,066 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E1D50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803E1D50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E1D50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E1D50>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:20,067 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E3820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191803E3820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E3820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191803E3820>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:25,019 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F09A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F09A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F09A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F09A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:25,023 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F24A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F24A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F24A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=health_redis (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F24A0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:25,026 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F0E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F0E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F0E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=MayoSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F0E20>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:25,033 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2C80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F2C80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2C80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 305, in job_list
    result = scrapyd.list_jobs(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 139, in list_jobs
    jobs = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 37, in request
    response = super(Client, self).request(*args, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: /listjobs.json?project=HopkinsSpider (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2C80>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:28,999 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052C4F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x000001918052C4F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052C4F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 171, in client_status
    requests.get(scrapyd_url(client.ip, client.port), timeout=3)
  File "E:\python\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "E:\python\lib\site-packages\requests\api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001918052C4F0>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
ERROR - 2022-05-31 13:11:31,690 - process: 15832 - utils.py - polls.utils - 84 - utils - HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2020>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connection.py", line 174, in _new_conn
    conn = connection.create_connection(
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 95, in create_connection
    raise err
  File "E:\python\lib\site-packages\urllib3\util\connection.py", line 85, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 703, in urlopen
    httplib_response = self._make_request(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File "E:\python\lib\site-packages\urllib3\connection.py", line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File "E:\python\lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "E:\python\lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "E:\python\lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "E:\python\lib\http\client.py", line 975, in send
    self.connect()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 205, in connect
    conn = self._new_conn()
  File "E:\python\lib\site-packages\urllib3\connection.py", line 186, in _new_conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x00000191802F2020>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\python\lib\site-packages\requests\adapters.py", line 440, in send
    resp = conn.urlopen(
  File "E:\python\lib\site-packages\urllib3\connectionpool.py", line 785, in urlopen
    retries = retries.increment(
  File "E:\python\lib\site-packages\urllib3\util\retry.py", line 592, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2020>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 171, in client_status
    requests.get(scrapyd_url(client.ip, client.port), timeout=3)
  File "E:\python\lib\site-packages\requests\api.py", line 75, in get
    return request('get', url, params=params, **kwargs)
  File "E:\python\lib\site-packages\requests\api.py", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 529, in request
    resp = self.send(prep, **send_kwargs)
  File "E:\python\lib\site-packages\requests\sessions.py", line 645, in send
    r = adapter.send(request, **kwargs)
  File "E:\python\lib\site-packages\requests\adapters.py", line 519, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=6800): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000191802F2020>: Failed to establish a new connection: [WinError 10061] 由于目标计算机积极拒绝，无法连接。'))
INFO - 2022-05-31 13:11:50,864 - process: 15832 - build.py - polls.build - 24 - build - successfully build project HopkinsSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\HopkinsSpider\HopkinsSpider-1.0-py3.10.egg
ERROR - 2022-05-31 13:11:58,141 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-gheitx0d.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-gheitx0d.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 13:17:23,516 - process: 15832 - build.py - polls.build - 24 - build - successfully build project MayoSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\MayoSpider\MayoSpider-1.0-py3.10.egg
ERROR - 2022-05-31 13:17:31,724 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-48i23s2n.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-48i23s2n.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 13:18:23,958 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-y4afg5nn.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-y4afg5nn.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 13:22:48,076 - process: 15832 - utils.py - polls.utils - 84 - utils - Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 752, in project_file_update
    data = json.loads(request.body)
  File "E:\python\lib\site-packages\rest_framework\request.py", line 416, in __getattr__
    return getattr(self._request, attr)
  File "E:\python\lib\site-packages\django\http\request.py", line 335, in body
    raise RequestDataTooBig(
django.core.exceptions.RequestDataTooBig: Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.
ERROR - 2022-05-31 13:23:20,174 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-zczpw3cr.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-zczpw3cr.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 13:25:59,959 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-kyi57b73.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-kyi57b73.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 13:28:21,311 - process: 15832 - utils.py - polls.utils - 84 - utils - Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 752, in project_file_update
    data = json.loads(request.body)
  File "E:\python\lib\site-packages\rest_framework\request.py", line 416, in __getattr__
    return getattr(self._request, attr)
  File "E:\python\lib\site-packages\django\http\request.py", line 335, in body
    raise RequestDataTooBig(
django.core.exceptions.RequestDataTooBig: Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.
INFO - 2022-05-31 13:43:56,604 - process: 15832 - build.py - polls.build - 24 - build - successfully build project health_redis to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\health_redis\project-1.0-py3.10.egg
INFO - 2022-05-31 13:44:08,892 - process: 15832 - build.py - polls.build - 24 - build - successfully build project HopkinsSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\HopkinsSpider\HopkinsSpider-1.0-py3.10.egg
ERROR - 2022-05-31 13:44:15,361 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-ht33vii2.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-ht33vii2.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 13:52:54,908 - process: 15832 - build.py - polls.build - 24 - build - successfully build project health_redis to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\health_redis\project-1.0-py3.10.egg
ERROR - 2022-05-31 13:53:04,103 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-cb8gbr8u.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-cb8gbr8u.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 13:53:22,912 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-xsulscbo.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-xsulscbo.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 13:54:09,230 - process: 15832 - build.py - polls.build - 24 - build - successfully build project health_redis to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\health_redis\project-1.0-py3.10.egg
ERROR - 2022-05-31 13:54:16,536 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-jbx78ga5.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-jbx78ga5.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 13:55:33,728 - process: 15832 - build.py - polls.build - 24 - build - successfully build project MayoSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\MayoSpider\MayoSpider-1.0-py3.10.egg
ERROR - 2022-05-31 13:55:41,266 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-7hy15pp9.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-7hy15pp9.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 14:02:00,828 - process: 15832 - build.py - polls.build - 24 - build - successfully build project MayoSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\MayoSpider\MayoSpider-1.0-py3.10.egg
INFO - 2022-05-31 14:02:14,051 - process: 15832 - build.py - polls.build - 24 - build - successfully build project MayoSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\MayoSpider\MayoSpider-1.0-py3.10.egg
ERROR - 2022-05-31 14:02:20,409 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-sqnm6xmm.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-sqnm6xmm.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 14:06:45,975 - process: 15832 - build.py - polls.build - 24 - build - successfully build project MayoSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\MayoSpider\MayoSpider-1.0-py3.10.egg
ERROR - 2022-05-31 14:06:54,630 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-sbnpd1mq.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-sbnpd1mq.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 14:13:18,313 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-lfandq7y.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-lfandq7y.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

INFO - 2022-05-31 14:15:18,137 - process: 15832 - build.py - polls.build - 24 - build - successfully build project MayoSpider to egg file E:\5703\git_nlp_repository\COMP5703CS65_NLP\projects\MayoSpider\MayoSpider-1.0-py3.10.egg
ERROR - 2022-05-31 14:15:33,900 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-ralk21yf.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-ralk21yf.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

ERROR - 2022-05-31 14:24:43,198 - process: 15832 - utils.py - polls.utils - 84 - utils - Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-vm43du2t.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)
Traceback (most recent call last):
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\utils.py", line 82, in wrapper
    result = func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\decorators\csrf.py", line 54, in wrapped_view
    return view_func(*args, **kwargs)
  File "E:\python\lib\site-packages\django\views\generic\base.py", line 84, in view
    return self.dispatch(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 509, in dispatch
    response = self.handle_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 469, in handle_exception
    self.raise_uncaught_exception(exc)
  File "E:\python\lib\site-packages\rest_framework\views.py", line 480, in raise_uncaught_exception
    raise exc
  File "E:\python\lib\site-packages\rest_framework\views.py", line 506, in dispatch
    response = handler(request, *args, **kwargs)
  File "E:\python\lib\site-packages\rest_framework\decorators.py", line 50, in handler
    return func(*args, **kwargs)
  File "E:\5703\git_nlp_repository\COMP5703CS65_NLP\polls\views.py", line 236, in spider_list
    spiders = scrapyd.list_spiders(project_name)
  File "E:\python\lib\site-packages\scrapyd_api\wrapper.py", line 158, in list_spiders
    json = self.client.get(url, params=params, timeout=self.timeout)
  File "E:\python\lib\site-packages\requests\sessions.py", line 542, in get
    return self.request('GET', url, **kwargs)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 38, in request
    return self._handle_response(response)
  File "E:\python\lib\site-packages\scrapyd_api\client.py", line 34, in _handle_response
    raise ScrapydResponseError(json['message'])
scrapyd_api.exceptions.ScrapydResponseError: Traceback (most recent call last):
  File "E:\python\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "E:\python\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 46, in <module>
    main()
  File "E:\python\lib\site-packages\scrapyd\runner.py", line 43, in main
    execute()
  File "E:\python\lib\site-packages\scrapy\cmdline.py", line 144, in execute
    cmd.crawler_process = CrawlerProcess(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 290, in __init__
    super().__init__(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 167, in __init__
    self.spider_loader = self._get_spider_loader(settings)
  File "E:\python\lib\site-packages\scrapy\crawler.py", line 161, in _get_spider_loader
    return loader_cls.from_settings(settings.frozencopy())
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 67, in from_settings
    return cls(settings)
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 24, in __init__
    self._load_all_spiders()
  File "E:\python\lib\site-packages\scrapy\spiderloader.py", line 51, in _load_all_spiders
    for module in walk_modules(name):
  File "E:\python\lib\site-packages\scrapy\utils\misc.py", line 80, in walk_modules
    mod = import_module(path)
  File "E:\python\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "c:\users\shinelon\appdata\local\temp\health-1653960149-vm43du2t.egg\health\spiders\__init__.py", line 2, in <module>
  File "E:\python\lib\site-packages\scrapy_redis\spiders.py", line 4, in <module>
    from collections import Iterable
ImportError: cannot import name 'Iterable' from 'collections' (E:\python\lib\collections\__init__.py)

